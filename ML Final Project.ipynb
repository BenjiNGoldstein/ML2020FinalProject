{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDC collects data yearly on American health through the National Health Interview Survey (NHIS). This survey contains ten's of thousands of records each year across about a hundred questions relating to the health of people. While the most recent data is unavailable to the public, a few years back the majority of it is accessable here https://www.cdc.gov/nchs/nhis/index.htm. While this data is theoretically useful, not much has been done with it because it is unwieldy and difficult to work with. Rather than trying to use a large amount of it, the goal of this project is to predict some or all of the 9 questions relating to food. Some of them are binary, \"Could you afford to eat balanced meals\" and some are more complexe \"In the last week how many days did you not eat\". Using this data can be used to locate where food aid needs to be sent, or what indicators imply a difficult life for students.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NHIS data is distributed across a variety of files. The household file which contains some data related to the household. There is very little data here, the type of living quarters, which of the 4 regions in the US they are located in, or how many people in the household responded. The family file contains much better data, the target questions, questions about medical history, and questions about financial circumstances.\n",
    "\n",
    "These two main files, and the other child and adult records can be combined through the Household Number identifier.\n",
    "\n",
    "This is all data from the 2018 survey, the most recent to be released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FINT_Y_P</th>\n",
       "      <th>FINT_M_P</th>\n",
       "      <th>FMX</th>\n",
       "      <th>RECTYPE_x</th>\n",
       "      <th>SRVY_YR_x</th>\n",
       "      <th>HHX</th>\n",
       "      <th>FM_SIZE</th>\n",
       "      <th>FM_STRCP</th>\n",
       "      <th>FM_TYPE</th>\n",
       "      <th>FM_STRP</th>\n",
       "      <th>...</th>\n",
       "      <th>ACPT_FAM</th>\n",
       "      <th>NON_INTV</th>\n",
       "      <th>RECTYPE_y</th>\n",
       "      <th>SRVY_YR_y</th>\n",
       "      <th>LIVQRT_P</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WTIA_HH</th>\n",
       "      <th>WTFA_HH</th>\n",
       "      <th>PSTRAT</th>\n",
       "      <th>PPSU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2417.5</td>\n",
       "      <td>3338</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2347.5</td>\n",
       "      <td>5188</td>\n",
       "      <td>137</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2775.8</td>\n",
       "      <td>5259</td>\n",
       "      <td>106</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2689.2</td>\n",
       "      <td>3204</td>\n",
       "      <td>117</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3113.6</td>\n",
       "      <td>4497</td>\n",
       "      <td>126</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30304</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>55556</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3943.9</td>\n",
       "      <td>4470</td>\n",
       "      <td>147</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30305</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>55557</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3964.5</td>\n",
       "      <td>7097</td>\n",
       "      <td>121</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30306</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>55560</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4417.5</td>\n",
       "      <td>7835</td>\n",
       "      <td>130</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30307</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>55562</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3950.2</td>\n",
       "      <td>6791</td>\n",
       "      <td>137</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30308</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2018</td>\n",
       "      <td>55563</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1034.8</td>\n",
       "      <td>1411</td>\n",
       "      <td>108</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30309 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FINT_Y_P  FINT_M_P  FMX  RECTYPE_x  SRVY_YR_x    HHX  FM_SIZE  \\\n",
       "0          2018         1    1         60       2018      1        1   \n",
       "1          2018         1    1         60       2018      4        3   \n",
       "2          2018         2    1         60       2018      6        4   \n",
       "3          2018         3    1         60       2018      8        3   \n",
       "4          2018         2    1         60       2018      9        1   \n",
       "...         ...       ...  ...        ...        ...    ...      ...   \n",
       "30304      2018        11    3         60       2018  55556        1   \n",
       "30305      2018        11    1         60       2018  55557        1   \n",
       "30306      2018        12    1         60       2018  55560        1   \n",
       "30307      2018        10    1         60       2018  55562        2   \n",
       "30308      2018        12    1         60       2018  55563        1   \n",
       "\n",
       "       FM_STRCP  FM_TYPE  FM_STRP  ...  ACPT_FAM  NON_INTV  RECTYPE_y  \\\n",
       "0            11        1       11  ...       1.0       NaN         10   \n",
       "1            41        4       41  ...       1.0       NaN         10   \n",
       "2            41        4       41  ...       1.0       NaN         10   \n",
       "3            41        4       41  ...       1.0       NaN         10   \n",
       "4            11        1       11  ...       1.0       NaN         10   \n",
       "...         ...      ...      ...  ...       ...       ...        ...   \n",
       "30304        12        1       12  ...       3.0       NaN         10   \n",
       "30305        11        1       11  ...       1.0       NaN         10   \n",
       "30306        11        1       11  ...       1.0       NaN         10   \n",
       "30307        21        2       21  ...       1.0       NaN         10   \n",
       "30308        11        1       11  ...       1.0       NaN         10   \n",
       "\n",
       "       SRVY_YR_y  LIVQRT_P  REGION  WTIA_HH  WTFA_HH  PSTRAT  PPSU  \n",
       "0           2018         1       3   2417.5     3338     103    19  \n",
       "1           2018         1       2   2347.5     5188     137    38  \n",
       "2           2018         1       3   2775.8     5259     106    22  \n",
       "3           2018         1       2   2689.2     3204     117    25  \n",
       "4           2018         1       3   3113.6     4497     126    34  \n",
       "...          ...       ...     ...      ...      ...     ...   ...  \n",
       "30304       2018         1       2   3943.9     4470     147    37  \n",
       "30305       2018         1       3   3964.5     7097     121     6  \n",
       "30306       2018         1       3   4417.5     7835     130    23  \n",
       "30307       2018         1       2   3950.2     6791     137    19  \n",
       "30308       2018         1       4   1034.8     1411     108   114  \n",
       "\n",
       "[30309 rows x 143 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "familydata = ps.read_csv('familyxxcsv/familyxx.csv')\n",
    "#familydata\n",
    "householddata = ps.read_csv('househldcsv/househld.csv')\n",
    "#householddata\n",
    "#These don't have the same number of columes, but can be merged on the HHX column, using default inner join\n",
    "data = familydata.merge(householddata,on='HHX')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 142 colums that contain actual data, there is way too much to just feed it all in. Ignoring the additional data that can be gathered from idividual records. So lets explore some some of the more plausible relations between some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x212673c0588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot.scatter(x='REGION',y='FSNOTEAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a totally useless plot as there isn't enough detail in a single pair of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2126895b3c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot.scatter(x='INCGRP5',y='FSNOTEAT',c='REGION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even trying to include wealth into the picture, it doesn't substantially affect the results, beyond some additional variablity. This is why this data set is so hard to work with, and why extracting any sort of information from it has value, because it would allow the CDC to make some accuracte assessments of the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FM_STRCP is a critical column, it describes what type of family is located in the household. It is a numerical value that represents a categorical thing, so some processing is required. That each of the codes means is decribed in the variable frequency data release.\n",
    "\n",
    "Some of the data is irrelevant, what month the data was gathered or the given ID number both must be dropped as part of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "familydata = ps.read_csv('familyxxcsv/familyxx.csv') #reload the family data set, so there is less overlap\n",
    "familydata = familydata.drop(columns=['FINT_Y_P','FINT_M_P','FMX','RECTYPE','SRVY_YR','HHX'])#drop the identifying information\n",
    "familydata = familydata.drop('WTFA_FAM',axis=1)#this is the weight of the family, ie how representative it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FM_SIZE</th>\n",
       "      <th>FM_STRCP</th>\n",
       "      <th>FM_TYPE</th>\n",
       "      <th>FM_STRP</th>\n",
       "      <th>TELN_FLG</th>\n",
       "      <th>CURWRKN</th>\n",
       "      <th>TELCELN</th>\n",
       "      <th>WRKCELN</th>\n",
       "      <th>PHONEUSE</th>\n",
       "      <th>FLNGINTV</th>\n",
       "      <th>...</th>\n",
       "      <th>COVCONF</th>\n",
       "      <th>FHICOST</th>\n",
       "      <th>FMEDBILL</th>\n",
       "      <th>FMEDBPAY</th>\n",
       "      <th>FMEDBNOP</th>\n",
       "      <th>FSAF</th>\n",
       "      <th>FHICOVCT</th>\n",
       "      <th>FHICOVYN</th>\n",
       "      <th>FPRCOOH</th>\n",
       "      <th>FHIEBCCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30304</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30305</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30306</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30307</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30308</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30309 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FM_SIZE  FM_STRCP  FM_TYPE  FM_STRP  TELN_FLG  CURWRKN  TELCELN  \\\n",
       "0            1        11        1       11         1      1.0        1   \n",
       "1            3        41        4       41         1      2.0        1   \n",
       "2            4        41        4       41         1      2.0        1   \n",
       "3            3        41        4       41         1      2.0        1   \n",
       "4            1        11        1       11         1      2.0        1   \n",
       "...        ...       ...      ...      ...       ...      ...      ...   \n",
       "30304        1        12        1       12         1      2.0        1   \n",
       "30305        1        11        1       11         1      1.0        1   \n",
       "30306        1        11        1       11         1      2.0        1   \n",
       "30307        2        21        2       21         1      1.0        1   \n",
       "30308        1        11        1       11         1      2.0        1   \n",
       "\n",
       "       WRKCELN  PHONEUSE  FLNGINTV  ...  COVCONF  FHICOST  FMEDBILL  FMEDBPAY  \\\n",
       "0          1.0       3.0         1  ...      NaN        1         2         2   \n",
       "1          3.0       NaN         1  ...      4.0        2         1         1   \n",
       "2          2.0       NaN         1  ...      1.0        2         2         2   \n",
       "3          2.0       NaN         1  ...      3.0        3         2         1   \n",
       "4          1.0       NaN         1  ...      NaN        2         1         1   \n",
       "...        ...       ...       ...  ...      ...      ...       ...       ...   \n",
       "30304      1.0       NaN         1  ...      1.0        1         2         2   \n",
       "30305      1.0       1.0         1  ...      NaN        2         1         2   \n",
       "30306      1.0       NaN         1  ...      4.0        5         1         1   \n",
       "30307      2.0       1.0         1  ...      2.0        2         2         2   \n",
       "30308      1.0       NaN         1  ...      NaN        1         2         2   \n",
       "\n",
       "       FMEDBNOP  FSAF  FHICOVCT  FHICOVYN  FPRCOOH  FHIEBCCT  \n",
       "0           NaN     2         1         1      NaN       NaN  \n",
       "1           1.0     2         3         1      2.0       3.0  \n",
       "2           NaN     1         4         1      2.0       4.0  \n",
       "3           NaN     2         3         1      2.0       3.0  \n",
       "4           1.0     2         1         1      2.0       0.0  \n",
       "...         ...   ...       ...       ...      ...       ...  \n",
       "30304       NaN     2         1         1      NaN       1.0  \n",
       "30305       1.0     2         0         2      NaN       NaN  \n",
       "30306       2.0     2         1         1      2.0       1.0  \n",
       "30307       NaN     2         2         1      2.0       2.0  \n",
       "30308       NaN     2         1         1      2.0       0.0  \n",
       "\n",
       "[30309 rows x 120 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "familydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an example of a randomforest https://medium.com/@dineshmadhup_75545/comparison-of-tensorflow-and-random-forest-model-with-python-92a475f84faa\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Evaluations\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "familydata.fillna(0,inplace=True)\n",
    "#break off the possible goals\n",
    "goals = ['FSRUNOUT','FSLAST','FSBALANC','FSSKIP','FSSKDAYS','FSLESS','FSHUNGRY','FSWEIGHT','FSNOTEAT','FSNEDAYS']\n",
    "Y1 = familydata.filter(items=['FSLAST'])\n",
    "Y2 = familydata.filter(items=['FSSKIP'])\n",
    "Y3 = familydata.filter(items=['FSLESS'])\n",
    "other = familydata.columns.tolist()\n",
    "for col in goals:\n",
    "    other.remove(col)\n",
    "    \n",
    "\n",
    "X = familydata.filter(items=other)\n",
    "#find the other options\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y1)\n",
    "#print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.07      0.11       214\n",
      "           2       0.36      0.07      0.11       578\n",
      "           3       0.91      0.99      0.95      6783\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89      7578\n",
      "   macro avg       0.41      0.28      0.29      7578\n",
      "weighted avg       0.85      0.89      0.86      7578\n",
      "\n",
      "[[  14   26  174    0]\n",
      " [  13   39  526    0]\n",
      " [  12   44 6727    0]\n",
      " [   0    0    3    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#print(y_train)\n",
    "rf_model.fit(X_train,y_train.values.ravel())\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "print(classification_report(y_test,rf_prediction))\n",
    "print(confusion_matrix(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few options that are so poorly represented they should not be used, those are 7,8, and 9. So that leaves the 3 common values, 1 often true, 2 sometimes true, and 3 never true. As can be seen, these values are very low, and unlikely to be an actually good way to extrac information from this data.\n",
    "\n",
    "Looking at some easier to predict options, there is \"Cut size or skipped meals because not enough money\" or FSKDAYS Which is the number of days cut size or skipped meals. Eating less also has a much more reasonable split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      6412\n",
      "         1.0       0.51      0.21      0.30       437\n",
      "         2.0       0.33      0.07      0.11       729\n",
      "\n",
      "    accuracy                           0.85      7578\n",
      "   macro avg       0.57      0.42      0.45      7578\n",
      "weighted avg       0.80      0.85      0.81      7578\n",
      "\n",
      "[[6320   34   58]\n",
      " [ 303   93   41]\n",
      " [ 623   57   49]]\n"
     ]
    }
   ],
   "source": [
    "#Estimator for FSSKIP\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y2)\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#print(y_train)\n",
    "rf_model.fit(X_train,y_train.values.ravel())\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "print(classification_report(y_test,rf_prediction))\n",
    "print(confusion_matrix(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93      6445\n",
      "         1.0       0.45      0.23      0.30       424\n",
      "         2.0       0.34      0.05      0.09       707\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86      7578\n",
      "   macro avg       0.33      0.25      0.26      7578\n",
      "weighted avg       0.80      0.86      0.81      7578\n",
      "\n",
      "[[6353   55   37    0    0]\n",
      " [ 294   96   34    0    0]\n",
      " [ 608   63   36    0    0]\n",
      " [   1    0    0    0    0]\n",
      " [   0    1    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Estimator for FSLESS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y3)\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#print(y_train)\n",
    "rf_model.fit(X_train,y_train.values.ravel())\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "print(classification_report(y_test,rf_prediction))\n",
    "print(confusion_matrix(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after the simple random forest estimators, lets look at Neural Network classifiers since they are more likely to be able to actually use the multitude of variables to some effect. It is unlikely that this non-engineered data will actuall produce good results though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 1. 7.]\n",
      "[0. 2. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.99      0.93      6449\n",
      "         1.0       0.55      0.20      0.29       444\n",
      "         2.0       0.27      0.05      0.09       683\n",
      "\n",
      "    accuracy                           0.86      7576\n",
      "   macro avg       0.57      0.41      0.44      7576\n",
      "weighted avg       0.80      0.86      0.82      7576\n",
      "\n",
      "[[6374   28   47]\n",
      " [ 302   88   54]\n",
      " [ 603   43   37]]\n"
     ]
    }
   ],
   "source": [
    "#dropping the very race classes (7 and 9)\n",
    "oddresults = familydata[ familydata['FSLESS'] >= 7.0].index\n",
    "#nineres = familydata[ familydata['FSLESS'] == 9.0].index\n",
    "cleaneddata = familydata.drop(oddresults)\n",
    "#cleaneddata = familydata.drop(nineres)\n",
    "Y4 = cleaneddata.filter(items=['FSLESS'])\n",
    "X4 = cleaneddata.filter(items=other)\n",
    "print(Y4.FSLESS.unique())\n",
    "\n",
    "#Estimator for FSLESS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4,Y4)\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "#print(y_train)\n",
    "rf_model.fit(X_train,y_train.values.ravel())\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "print(classification_report(y_test,rf_prediction))\n",
    "print(confusion_matrix(y_test,rf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22726 samples\n",
      "Epoch 1/10\n",
      "22726/22726 [==============================] - 1s 38us/sample - loss: 0.6084 - accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4829 - accuracy: 0.8446\n",
      "Epoch 3/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4538 - accuracy: 0.8496\n",
      "Epoch 4/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4299 - accuracy: 0.8503\n",
      "Epoch 5/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4198 - accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4127 - accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4110 - accuracy: 0.8558\n",
      "Epoch 8/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4058 - accuracy: 0.8544\n",
      "Epoch 9/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4029 - accuracy: 0.8562\n",
      "Epoch 10/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4008 - accuracy: 0.8556\n",
      "7576/7576 - 0s - loss: 0.4390 - accuracy: 0.8460\n",
      "Test accuracy: 0.8459609\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#modified from https://www.tensorflow.org/tutorials/keras/classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4,Y4)\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(len(other)),keras.layers.Dense(30),keras.layers.Dense(3)])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train.to_numpy(),y_train.to_numpy(),epochs=10)\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose = 2)\n",
    "print(\"Test accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite almost no additional preprocessing, this gives much better results. Although just these results don't give a great deal of confidence that it isn't just overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22726 samples\n",
      "Epoch 1/10\n",
      "22726/22726 [==============================] - 1s 36us/sample - loss: 0.5566 - accuracy: 0.8413\n",
      "Epoch 2/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4247 - accuracy: 0.8524\n",
      "Epoch 3/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4068 - accuracy: 0.8549\n",
      "Epoch 4/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4018 - accuracy: 0.8552\n",
      "Epoch 5/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4037 - accuracy: 0.8559\n",
      "Epoch 6/10\n",
      "22726/22726 [==============================] - 1s 23us/sample - loss: 0.4011 - accuracy: 0.8569\n",
      "Epoch 7/10\n",
      "22726/22726 [==============================] - 1s 29us/sample - loss: 0.4026 - accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4013 - accuracy: 0.8577\n",
      "Epoch 9/10\n",
      "22726/22726 [==============================] - 1s 24us/sample - loss: 0.4007 - accuracy: 0.8574\n",
      "Epoch 10/10\n",
      "22726/22726 [==============================] - 1s 25us/sample - loss: 0.4003 - accuracy: 0.8567\n",
      "7576/7576 - 0s - loss: 0.4250 - accuracy: 0.8448\n",
      "Test accuracy: 0.844773\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(len(other)),keras.layers.Dense(15),keras.layers.Dense(15),keras.layers.Dense(3)])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train.to_numpy(),y_train.to_numpy(),epochs=10)\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose = 2)\n",
    "print(\"Test accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two different methods to look for a connection between household data and food consumption show different things. The simplistic idea of a random forest is terrible at actually identifying anything that isn't cut and dry. Since the 3 categories aren't even sort of in balance, with the null category domination all of the others, it is simply able to guess null most of the time, and get reasonable accuracy and recall. However the neural network options are bettle able to disambiguate between these limited categories. After trying a variety of different setups it doesn't seem to have that much impact on the final results. This means that I'm probably using too many nuerons in the middle hidden layers because there aren't that many important factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data from 2017\n",
    "family2017 = ps.read_csv('familyxxcsv/family17.csv') #reload the family data set, so there is less overlap\n",
    "family2017 = family2017.drop(columns=['FINT_Y_P','FINT_M_P','FMX','RECTYPE','SRVY_YR','HHX'])#drop the identifying information\n",
    "family2017 = family2017.drop('WTFA_FAM',axis=1)#this is the weight of the family, ie how representative it is\n",
    "\n",
    "goals = ['FSRUNOUT','FSLAST','FSBALANC','FSSKIP','FSSKDAYS','FSLESS','FSHUNGRY','FSWEIGHT','FSNOTEAT','FSNEDAYS']\n",
    "other = family2017.columns.tolist()\n",
    "for col in goals:\n",
    "    other.remove(col)\n",
    "#dropping the very race classes (7 and 9)\n",
    "oddresults = family2017[ family2017['FSLESS'] >= 7.0].index\n",
    "#nineres = familydata[ familydata['FSLESS'] == 9.0].index\n",
    "cleaneddata = family2017.drop(oddresults)\n",
    "#cleaneddata = familydata.drop(nineres)\n",
    "Y5 = cleaneddata.filter(items=['FSLESS'])\n",
    "X5 = cleaneddata.filter(items=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24859 samples\n",
      "Epoch 1/10\n",
      "   32/24859 [..............................] - ETA: 4:01"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of -9223372036854775808 which is outside the valid range of [0, 3).  Label values: -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 2 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 2 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808\n\t [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-14-9d4a0205ff40>:9) ]] [Op:__inference_distributed_function_669]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d4a0205ff40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\tensorflow_enc\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of -9223372036854775808 which is outside the valid range of [0, 3).  Label values: -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 2 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 2 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808 -9223372036854775808\n\t [[node loss/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-14-9d4a0205ff40>:9) ]] [Op:__inference_distributed_function_669]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#modified from https://www.tensorflow.org/tutorials/keras/classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X5,Y5)\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(len(other)),keras.layers.Dense(30),keras.layers.Dense(3)])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train.to_numpy(),y_train.to_numpy(),epochs=10)\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose = 2)\n",
    "print(\"Test accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was hoping to be able to compare the network trained on the 2018 data on the 2017 data, however the 2017 data seams far less uniform as that error shows.\n",
    "\n",
    "# Results\n",
    "Unsurprisingly there is enough data contained in just the family data set to be able to make fairly accurate predictions as to the availab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
